{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_normal_(tensor, mean=0, std=1):\n",
    "    size = tensor.shape\n",
    "    tmp = tensor.new_empty(size + (4,)).normal_()\n",
    "    valid = (tmp < 2) & (tmp > -2)\n",
    "    ind = valid.max(-1, keepdim=True)[1]\n",
    "    tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))\n",
    "    tensor.data.mul_(std).add_(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def attention_filter(attention_feature_map, kernel_size=3, mean=6, stddev=5):\n",
    "    attention_map = torch.abs(attention_feature_map)\n",
    "    \n",
    "    attention_mask = attention_map > 2 * torch.mean(attention_map)\n",
    "    attention_mask = attention_mask.float()\n",
    "    \n",
    "    w = torch.randn(kernel_size, kernel_size)\n",
    "    truncated_normal_(w, mean, stddev)\n",
    "    w = w / torch.sum(w)\n",
    "    \n",
    "    # [filter_height, filter_width, in_channels, out_channels]\n",
    "    w = torch.unsqueeze(w, 2)\n",
    "    w.repeat(1, 1, attention_mask.shape[3])\n",
    "    w = torch.unsqueeze(w, 3)\n",
    "    w.repeat(1, 1, 1, attention_mask.shape[3])\n",
    "    # attention_map = tf.nn.conv2d(attention_mask, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    gaussian_filter = nn.Conv2d(attention_mask.shape[1], attention_mask.shape[1], (kernel_size, kernel_size))\n",
    "    gaussian_filter.weight.data = w\n",
    "    gaussian_filter.weight.requires_grad = False\n",
    "    pad_filter = nn.Sequential(\n",
    "        nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "        gaussian_filter\n",
    "    )\n",
    "    attention_map = pad_filter(attention_mask)\n",
    "    attention_map = attention_map - torch.min(attention_map)\n",
    "    attention_map = attention_map / torch.max(attention_map)\n",
    "    return attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9., 10., 11.],\n",
       "        [12., 13., 14.],\n",
       "        [15., 16., 17.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(27).view(1, 3, 3, 3).float()\n",
    "a.mean(dim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0124, 0.0124, 0.0124, 0.0124, 0.0124],\n",
      "          [0.0124, 0.0124, 0.0124, 0.0124, 0.0124],\n",
      "          [0.0124, 0.0124, 0.0124, 0.0124, 0.0124],\n",
      "          [0.0124, 0.0124, 0.0124, 0.0124, 0.0124],\n",
      "          [0.0124, 0.0124, 0.0124, 0.0124, 0.0124]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]]]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = attention_filter(a)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26.)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
